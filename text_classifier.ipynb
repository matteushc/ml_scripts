{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import string\n",
    "\n",
    "mainPath = \"D:\\\\Users\\\\matteus-paula\\\\Documents\\\\Projetos\\\\python\\\\desafio_mprj\\\\desafio-ia\\\\energia\"\n",
    "\n",
    "targetnames = list()\n",
    "filenames = list()\n",
    "target = list()\n",
    "data = list()\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    change_str = only_ascii.decode(\"utf-8\")\n",
    "    change_str = re.sub(r\"[0-9]+\",\"\", change_str)\n",
    "    change_str = re.sub(r\"\\r|\\n|\\t\",\" \", change_str)\n",
    "    change_str = re.sub(r\"\\s\\s+\",\" \", change_str)\n",
    "    change_str = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\\\\\]^_`{|}~]+', \"\", change_str)\n",
    "    \n",
    "   \n",
    "    return change_str.lower()\n",
    "\n",
    "\n",
    "def load_data(targetnames, filenames, target, data, mainPath):\n",
    "\n",
    "    for folder in listdir(mainPath):\n",
    "        dir_folder = join(mainPath, folder)\n",
    "        if not isfile(dir_folder):\n",
    "            targetnames.append(folder)\n",
    "            for file in listdir(dir_folder):\n",
    "                file_path = join(dir_folder, file)\n",
    "                if isfile(file_path):\n",
    "                    target.append(targetnames.index(folder))\n",
    "                    filenames.append(file_path)\n",
    "                    with open(file_path, 'rb') as f:\n",
    "                        compressed_content = f.read()\n",
    "                    data.append(remove_accents(compressed_content.decode(\"utf-8\")))\n",
    "\n",
    "    return train_test_split(data, target, test_size=0.33, stratify=target, random_state=42)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data(targetnames, filenames, target, data, mainPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53384, 22017)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "stop_words_pt = get_stop_words('portuguese')\n",
    "\n",
    "count_vect = CountVectorizer(stop_words=stop_words_pt)\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53384, 22017)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53384, 22017)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'perigo de dano eletronico ficou evidenciado' => DanosEletrodomesticos\n",
      "'sob pena de multa' => InterrupcaoInstabilidadeFornecimento\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['perigo de dano eletronico ficou evidenciado', 'sob pena de multa']\n",
    "\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, targetnames[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['a', 'ao',...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words=stop_words_pt)),\n",
    "                     ('tfidf', TfidfTransformer()), \n",
    "                     ('clf', MultinomialNB()),])\n",
    "\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8716437210009889"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_test = X_test\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "KNeighborsClassifier      0.940113\n",
       "LinearSVC                 0.980237\n",
       "LogisticRegression        0.963435\n",
       "MultinomialNB             0.873575\n",
       "RandomForestClassifier    0.750710\n",
       "SGDClassifier             0.930822\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "    KNeighborsClassifier(n_neighbors=8),\n",
    "    SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, X_train_tfidf, y_train, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "cv_df.groupby('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9814786643340686"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer(stop_words=stop_words_pt)),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced'))),\n",
    "    \n",
    "])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           precision    recall  f1-score   support\n",
      "\n",
      "              CobrancaServicoNaoFornecido       0.93      0.76      0.84        54\n",
      "                        CobrancaSobAmeaca       0.98      0.99      0.98      3799\n",
      "                           CobrancaTarifa       0.42      0.86      0.56        44\n",
      "                    DanosEletrodomesticos       0.96      0.98      0.97      3886\n",
      "DificuldadeContratacaoRecusaInjustificada       0.88      0.92      0.90       304\n",
      "                  DificuldadeRenegociacao       0.62      0.42      0.50       101\n",
      "     InterrupcaoInstabilidadeFornecimento       0.99      0.99      0.99     18085\n",
      "                      NegativacaoIndevida       1.00      0.57      0.73        21\n",
      "\n",
      "                                micro avg       0.98      0.98      0.98     26294\n",
      "                                macro avg       0.85      0.81      0.81     26294\n",
      "                             weighted avg       0.98      0.98      0.98     26294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "s = set(y_test)\n",
    "target_names_test = [targetnames[i] for i in s]\n",
    "\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted,\n",
    "target_names=target_names_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 37,   1,   0,   0,   4,   5,   9,   0],\n",
       "       [  0, 331,   0,   3,   1,   1,   2,   0],\n",
       "       [  0,   2,  49,   1,   1,   1,   2,   0],\n",
       "       [  0,   4,   0, 308,   7,   0,  11,   0],\n",
       "       [  0,   6,   0,  10, 280,   0,   1,   0],\n",
       "       [  1,  39,   1,   4,   6,  34,   4,   1],\n",
       "       [  0,  25,   0,  15,   6,   3, 282,   0],\n",
       "       [  1,   4,   2,   0,   0,   2,   0,   8]], dtype=int64)"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
